# HuggingFace File Checker

I built this because I have thousands of LoRA files and wanted to check which ones I'm missing from various HuggingFace collections. Manually comparing was tedious, so this automates it. Also exports direct download URLs txt files for easy batch downloading.

![Example Output](example.png)

## What it does

Compares your local files against a HuggingFace repository using SHA256 hashes. Can export missing files, matches, mismatches, or all results. Additionally provides viewing/direct download URLs that can be exported for use with a downloader, also exportable.


Two modes:
1. **Metadata mode (default and recommended)** - Reads SHA256 from JSON metadata files (generated by [ComfyUI-Lora-Manager](https://github.com/willmiao/ComfyUI-Lora-Manager) or similar)
2. *[EXPERIMENTAL]* **Direct scan mode (`--scan-files`)** - Calculates SHA256 directly from your model files (Very slow and not recommended, but works without metadata), Not tested.
## Features

- **SHA256 Hash Comparison**: Verifies files by comparing SHA256 hashes (most reliable method)
- **Filename Matching**: Falls back to filename matching when SHA256 isn't available
- **Multiple Repository Types**: Supports models, datasets, and spaces
- **Safetensors Focus**: Option to check only `.safetensors` files
- **Smart Caching**: Caches parsed metadata for fast subsequent runs
- **Rich Output**: Beautiful terminal output with tables and progress indicators
- **Flexible Export**: Export missing files, matches, mismatches, download urls, or all results
- **Private Repos**: Supports HuggingFace API tokens for private repositories

## Setup

```bash
# Navigate to project directory
cd hf-file-checker

# Install dependencies
pip install -r requirements.txt
```

### Requirements
- Python 3.8+
- `huggingface_hub` - Official HuggingFace library for API access
- `rich` - Beautiful terminal formatting
- `click` - Command-line interface
- `requests` - HTTP client
- `ComfyUI-Lora-Manager` (optional but recommended, for generating metadata JSONs) [ComfyUI-Lora-Manager](https://github.com/willmiao/ComfyUI-Lora-Manager)

## Usage

### Recommended Usage
Generate metadata JSON files using [ComfyUI-Lora-Manager](https://github.com/willmiao/ComfyUI-Lora-Manager) first, then use this tool to compare.

```bash
# Recommended command
python src/main.py --hf-url "https://huggingface.co/user/exampleloras/tree/main" --local-dir "path/to/your/loras" --safetensors-only --export-all "./results"
```

### Basic Usage

```bash
# Using HuggingFace URL (auto-detects repo type)
python src/main.py --hf-url "https://huggingface.co/user/exampleloras/tree/main" --local-dir "path/to/your/loras"

# Using repository ID
python src/main.py --hf-repo "user/exampleloras" --local-dir "path/to/your/loras"

# Using repo ID with explicit type
python src/main.py --hf-repo "username/my-dataset" --repo-type dataset --local-dir "./data"

# Export all results to a directory
python src/main.py --hf-repo "user/exampleloras" --local-dir "path/to/your/loras" --export-all "./results"

```
### Options Examples

```bash
# Check only safetensors files
python src/main.py --hf-repo "user/exampleloras" --local-dir "path/to/your/loras" --safetensors-only

# Verbose output showing all matches
python src/main.py --hf-repo "user/exampleloras" --local-dir "path/to/your/loras" -v

# Force re-scan (ignore cache)
python src/main.py --hf-repo "user/exampleloras" --local-dir "path/to/your/loras" --no-cache

# Clear cache and run fresh
python src/main.py --hf-repo "user/exampleloras" --local-dir "path/to/your/loras" --clear-cache

# Using API token for private repos
python src/main.py --hf-repo "user/private-repo" --local-dir "path/to/your/metadata" --token "hf_xxxxx"

# Or set environment variable
export HF_TOKEN="hf_xxxxx" # set for per session, for permanent add to system env vars
python src/main.py --hf-repo "user/private-repo" --local-dir "path/to/your/metadata"
```

## Options

```
--hf-url           HuggingFace URL (auto-detects if it's a model/dataset/space)
--hf-repo          Repo ID like "username/repo-name"
--repo-type        Force repo type: model, dataset, space when using --hf-repo
--local-dir        Where your files are (required)
--safetensors-only Only check .safetensors files
--filter           Only check HF files matching a pattern (see below)
--export-missing   Save missing files list to a file
--export-urls      Save download URLs only (one per line, for aria2c/wget)
--export-matches   Save matched files list  
--export-all       Dump everything to a directory
--no-cache         Skip the cache (slower but fresh)
--clear-cache      Wipe the cache file
--token            HF token for private repos (or set HF_TOKEN env var)
--branch           Check a specific branch (default: main)
-v, --verbose      Show all matches, not just summary

--scan-files       Hash model files instead of reading metadata JSONs 
(slower, but works without metadata. Shows progress bar when hashing)
```

### Filter Patterns

The `--filter` option uses wildcard patterns:
- `*` matches any characters (zero or more)
- `?` matches exactly one character

Examples:
```bash
--filter "*wan22*"     # contains "wan22" anywhere
--filter "wan22*"      # starts with "wan22"
--filter "*-v2.safetensors"  # ends with "-v2.safetensors"
```

## Expected Metadata JSON Format

Your local metadata JSON files should contain at least these fields:

```json
{
  "file_name": "some_lora_v1",
  "file_path": "H:/AI/ComfyUI/models/loras/some_lora_v1.safetensors",
  "sha256": "e1c406154fbbe16b7604ab2ae89b9c8ecd9e7213664eaa9a4437c33626e93a6f",
  "size": 306808576
}
```

The tool will scan all `.json` files in the specified directory (recursively) and extract:
- `sha256` - Used for exact matching (preferred)
- `file_name` or `file_path` - Used for fallback matching by name

## Output

The tool provides a summary showing:

- ✓ **Matches**: Files verified by SHA256 hash
- ⚠ **Name matches only**: Filename matches but SHA256 couldn't be verified  
- ✗ **Mismatches**: Filename matches but SHA256 differs (different version?)
- ↓ **Missing locally**: Files on HuggingFace that you don't have

## How It Works

1. **Fetches HuggingFace Repository Files**: Uses the `huggingface_hub` library to get file metadata including SHA256 hashes (stored as LFS OID for large files). Supports model, dataset, and space repositories.

2. **Scans Local Metadata**: Recursively scans your local directory for JSON files containing file metadata. Uses smart caching (stored in `.hf_checker_cache.pkl`) to speed up subsequent runs.

3. **Compares Files**: 
   - First tries to match by SHA256 hash (most reliable)
   - Falls back to filename matching
   - Reports any discrepancies

   

## Caching
The tool caches parsed metadata in a `.hf_checker_cache.pkl` file in your local directory. This significantly speeds up subsequent runs when scanning large collections (e.g., 5000+ files).

- Cache validates by file modification time and size
- Use `--no-cache` to bypass cache for a single run
- Use `--clear-cache` to delete cache and start fresh
- Cache is automatically invalidated when files change


Both modes cache results so subsequent runs are fast:
- Metadata mode: `.hf_checker_cache.pkl`
- Direct scan mode: `.hf_checker_direct_cache.pkl`

Cache invalidates automatically when files change (checks mtime + size).

## Known limitations

- Direct file scanning is  very slow for large files and liberaries (~30s for a 6GB model), but results are cached
- Some HF files don't have SHA256 (non-LFS files), falls back to name matching

## Troubleshooting

### "No SHA256 found for files"
Some files on HuggingFace may not have SHA256 hashes available (non-LFS files). The tool will fall back to filename matching for these.

### "Rate limited"
If you're making many requests, you may be rate limited. Use a HuggingFace API token to increase limits:
```bash
export HF_TOKEN="your_token_here"
```

### Private Repository Access
For private repositories, you need to provide an API token with read access to the repository.

## License

GPL v3 - free to use and modify, but any modifications must also be open source.